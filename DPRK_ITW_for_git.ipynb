{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Set up: Data Acqusition - Raw Transaction Layer\n",
        "\n"
      ],
      "metadata": {
        "id": "FZ6HubuieXE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing relavent python libraries\n",
        "import requests\n",
        "import json\n",
        "import polars as pl\n",
        "from google.colab import userdata\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "GN2NIse_l5zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting up folders\n",
        "if os.path.exists(\"/content/sample_data/Output/\"):\n",
        "  pass\n",
        "else:\n",
        "  os.makedirs(\"/content/sample_data/Output/\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "g0zH67BTl8Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0xWoOtgSKOc",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#list of wallet addressess associated with DPRK ITW\n",
        "with open (\"/content/sample_data/wallet_addr.json\", \"r\") as f:\n",
        "  wallet_dataset = json.load(f)\n",
        "  print(wallet_dataset)\n",
        "\n",
        "  api_key = userdata.get('etherscankey')\n",
        "\n",
        "\n",
        "#For each wallet assessed to be associated with DPRK IT worker activity,\n",
        "#the most recent transactions are retrieved via the Etherscan API.\n",
        "\n",
        "for wallet in wallet_dataset:\n",
        "  transactions_api = f\"https://api.etherscan.io/v2/api\"\\\n",
        "    f\"?chainid=1\"\\\n",
        "    f\"&module=account\"\\\n",
        "    f\"&action=txlist\"\\\n",
        "    f\"&address={wallet}\"\\\n",
        "    f\"&startblock=0\"\\\n",
        "    f\"&endblock=99999999\"\\\n",
        "    f\"&page=1\"\\\n",
        "    f\"&offset=1000\"\\\n",
        "    f\"&sort=desc\"\\\n",
        "    f\"&apikey={api_key}\"\n",
        "  print(f\"Getting transactions for {wallet}\")\n",
        "\n",
        "  response = requests.get(transactions_api).json()\n",
        "  if response['message'] == 'No transactions found':\n",
        "    print(f\"No transactions found for {wallet}\")\n",
        "    continue\n",
        "\n",
        "\n",
        "  with open(f\"/content/sample_data/Output/{wallet}_transactions.json\", \"w\") as f:\n",
        "    f.write(json.dumps(response['result']))\n",
        "  time.sleep(0.25)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Storage & Query Layer (DuckDB as Analytical Engine)"
      ],
      "metadata": {
        "id": "ItX4JxNsekpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb as db\n",
        "\n",
        "#A raw, unmodified data layer is preserved to ensure reproducibility and separation\n",
        "#from downstream analytical assumptions\n",
        "raw_transactions_df = db.sql('''\n",
        "              SELECT *\n",
        "              FROM read_json('/content/sample_data/Output/*.json', union_by_name = true);''').df()\n",
        "display(raw_transactions_df)\n",
        "\n",
        "wallet_address_df = db.sql('''\n",
        "SELECT lower(json) as wallet_address\n",
        "FROM read_json('/content/sample_data/wallet_addr.json');''').df()\n",
        "\n"
      ],
      "metadata": {
        "id": "Rd-tS0F2exL-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Normalisation & Deduplication"
      ],
      "metadata": {
        "id": "pjqll50l021o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Raw transaction payloads include several fields (e.g., gas metrics, method identifiers)\n",
        "#that are not analytically relevant to behavioural analysis. They are excluded to reduce noise\n",
        "\n",
        "clean_dataset_df = db.sql('''\n",
        "SELECT DISTINCT\n",
        "hash AS tx_hash,\n",
        "CAST(value AS DOUBLE)/1e18 AS value_eth,\n",
        "to_timestamp (CAST(timeStamp AS BIGINT)) AS ts,\n",
        "lower(\"from\") AS from_address,\n",
        "lower(\"to\") AS to_address\n",
        "FROM raw_transactions_df;''').df()\n",
        "\n",
        "\n",
        "#Duplicate transaction hashes are removed to account for interactions between wallets\n",
        "#under to preventing an inflation of transaction counts and value metrics\n",
        "\n",
        "clean_dataset_df_1 = db.sql('''\n",
        "WITH txs AS (\n",
        "SELECT\n",
        "COUNT(*) OVER (PARTITION BY hash) AS tx_count,\n",
        "hash AS tx_hash,\n",
        "CAST(value AS DOUBLE)/1e18 AS value_eth,\n",
        "to_timestamp (CAST(timeStamp AS BIGINT)) AS ts,\n",
        "lower(\"from\") AS from_address,\n",
        "lower(\"to\") AS to_address\n",
        "FROM raw_transactions_df\n",
        ")\n",
        "SELECT DISTINCT *\n",
        "FROM txs\n",
        "WHERE tx_count = 2;''').df()\n",
        "\n",
        "\n",
        "#Timestamp normalisation to identify first and last transaction timestamp\n",
        "max_timestamp = db.sql('''\n",
        "SELECT MAX(ts) AS max_ts FROM clean_dataset_df;''').df()['max_ts'].iloc[0]\n",
        "min_timestamp = db.sql('''\n",
        "SELECT MIN(ts) AS min_ts FROM clean_dataset_df;''').df()['min_ts'].iloc[0]\n",
        "\n"
      ],
      "metadata": {
        "id": "SBvM3G__0xT4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transaction Flow Classification (Inbound vs Outbound)"
      ],
      "metadata": {
        "id": "ijx_2kc7uJV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Transactions are classified as inbound or outbound relative to each wallet of interest\n",
        "\n",
        "#Inbound flows are treated as on-chain revenue indicators\n",
        "inbound_flows_df = db.sql('''\n",
        "SELECT\n",
        "t1.tx_hash,\n",
        "t1.ts,\n",
        "t1.to_address AS wallet_address, -- The wallet receiving the funds\n",
        "t1.from_address AS sender_address, -- The sender of the funds\n",
        "t1.value_eth\n",
        "FROM clean_dataset_df as t1\n",
        "INNER JOIN wallet_address_df as t2\n",
        "ON t1.to_address = t2.wallet_address;''').df()\n",
        "\n",
        "#Sanity check to ensure each transaction hash appears only once in the inbound flows\n",
        "sanity_check_inbound_df = db.sql('''\n",
        "SELECT DISTINCT\n",
        "COUNT(*) OVER (PARTITION BY tx_hash) AS transaction_count, -- Count occurrences of each tx_hash\n",
        "tx_hash\n",
        "FROM inbound_flows_df\n",
        "GROUP BY tx_hash;''').df()\n",
        "\n",
        "#Outbound flows are analysed as potential laundering, redistribution, or cash-out events\n",
        "outbound_flows_df = db.sql('''\n",
        "SELECT\n",
        "t1.tx_hash,\n",
        "t1.ts,\n",
        "t1.from_address AS wallet_address, -- The wallet sending the funds\n",
        "t1.to_address AS recipient_address, -- The recipient of the funds\n",
        "t1.value_eth\n",
        "FROM clean_dataset_df as t1\n",
        "INNER JOIN wallet_address_df as t2\n",
        "ON t1.from_address = t2.wallet_address;''').df()\n",
        "\n",
        "#Sanity check to ensure each transaction hash appears only once in the outbound flows\n",
        "sanity_check_outbound_df = db.sql('''\n",
        "SELECT DISTINCT\n",
        "COUNT(*) OVER (PARTITION BY tx_hash) AS transaction_count, -- Count occurrences of each tx_hash\n",
        "tx_hash\n",
        "FROM outbound_flows_df\n",
        "GROUP BY tx_hash;''').df()\n",
        "\n",
        "#NOTE:This separation forms the analytical basis for subsequent behavioural and temporal assessments"
      ],
      "metadata": {
        "id": "-Tmnj7iNWTRA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualisation of Transactional Flows"
      ],
      "metadata": {
        "id": "pjA91RCFtg_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Aggregate inbound and outbound flows to create a stacked bar chart\n",
        "import pandas as pd\n",
        "\n",
        "#Aggregate inbound flows: calculate the total ETH value received by each wallet\n",
        "agg_inbound_flows_df = db.sql('''\n",
        "SELECT\n",
        "wallet_address,\n",
        "SUM(value_eth) AS value_eth,\n",
        "'Inbound' AS flow_type\n",
        "FROM inbound_flows_df\n",
        "GROUP BY wallet_address;''').df()\n",
        "\n",
        "#Aggregate outbound flows: calculate the total ETH value sent from each wallet\n",
        "agg_outbound_flows_df = db.sql('''\n",
        "SELECT\n",
        "wallet_address,\n",
        "SUM(value_eth) AS value_eth,\n",
        "'Outbound' AS flow_type\n",
        "FROM outbound_flows_df\n",
        "GROUP BY wallet_address\n",
        "ORDER BY value_eth DESC;''').df()\n",
        "\n",
        "#Combine inbound and outbound aggregated data into a single DataFrame for plotting\n",
        "stacked_bar_data = pd.concat([agg_inbound_flows_df, agg_outbound_flows_df])\n",
        "\n",
        "#Filter for wallets with significant ETH value (> 1 ETH) for clearer visuals\n",
        "stacked_bar_data_1 = db.sql('''\n",
        "SELECT *,\n",
        "FROM stacked_bar_data\n",
        "WHERE value_eth > 1;''').df()\n",
        "\n",
        "\n",
        "#Filter for wallets with very small ETH value (< 1 ETH)\n",
        "stacked_bar_data_2 = db.sql('''\n",
        "SELECT *,\n",
        "FROM stacked_bar_data\n",
        "WHERE value_eth < 1;''').df()\n",
        "\n",
        "\n",
        "#Identify wallets that have both inbound and outbound flows (count_wallet_address > 1)\n",
        "stacked_bar_data_3 = db.sql('''\n",
        "WITH sbd AS (\n",
        "SELECT *,\n",
        "COUNT(wallet_address) OVER (PARTITION BY wallet_address) AS count_wallet_address,\n",
        "FROM stacked_bar_data\n",
        ")\n",
        "SELECT *\n",
        "FROM sbd\n",
        "--WHERE count_wallet_address > 1\n",
        ";''').df()\n",
        "\n",
        "\n",
        "stacked_bar_data_4 = db.sql('''\n",
        "WITH sbd4 AS (\n",
        "SELECT  flow_type, SUM(value_eth) AS total_value_eth\n",
        "FROM stacked_bar_data_3\n",
        "GROUP BY flow_type\n",
        ")\n",
        "SELECT *, (total_value_eth/SUM(total_value_eth) OVER())*100 AS percentage_value\n",
        "FROM sbd4\n",
        ";''').df()\n",
        "\n",
        "\n",
        "#visualisation\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "labels = ['Outbound','Inbound']\n",
        "values = [78.230472, 21.769528]\n",
        "\n",
        "fig = go.Figure(data=[go.Pie(labels=labels, values=values, pull=[0, 0.2])])\n",
        "fig.update_layout(title_text='Percentage of Inbound vs Outbound ETH Value per Wallet')\n"
      ],
      "metadata": {
        "id": "-xwHo1UpI3T4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Temporal Behaviour Analysis (Payment Intervals) & Visualisation"
      ],
      "metadata": {
        "id": "ZCqYDnONWpco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Outbound transactions are ordered chronologically per wallet, and inter-payment\n",
        "#time deltas are computed to quantify gaps between successive transfers\n",
        "\n",
        "payment_intervals_df_1= db.sql('''\n",
        "WITH t1 AS (\n",
        "SELECT\n",
        "wallet_address,\n",
        "ts, LAG(ts) OVER (PARTITION BY wallet_address ORDER BY ts) AS previous_ts,\n",
        "date_diff('minute', LAG(ts) OVER (PARTITION BY wallet_address ORDER BY ts), ts) AS time_since_last_transaction,\n",
        "date_diff('day', LAG(ts) OVER (PARTITION BY wallet_address ORDER BY ts), ts) AS days_since_last,\n",
        "value_eth,\n",
        "FROM outbound_flows_df\n",
        ")\n",
        "SELECT *,\n",
        "CASE\n",
        "WHEN days_since_last >= 1 THEN '>=1 Days'\n",
        "WHEN days_since_last <1 THEN '0 Days'\n",
        "ELSE 'No Days'\n",
        "END AS periodicity_group\n",
        "FROM t1;''').df()\n",
        "\n",
        "\n",
        "ratio_df = db.sql('''\n",
        "WITH r1 AS (\n",
        "SELECT COUNT(*) AS grouped_rows, periodicity_group\n",
        "FROM payment_intervals_df_1\n",
        "GROUP BY periodicity_group\n",
        ")\n",
        "SELECT *,\n",
        "SUM (grouped_rows) OVER() AS total_rows,\n",
        "ROUND(grouped_rows/SUM (grouped_rows) OVER(),4)*100 AS ratio\n",
        "FROM r1;''').df()\n",
        "\n",
        "\n",
        "\n",
        "#Visualisaion - A donut chart of days_since_last_past\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "labels = ['No Days','>=1 Days','0 Days']\n",
        "values = [15.47, 29.52, 55.01]\n",
        "\n",
        "fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])\n",
        "fig.update_layout(title_text='Payment Intervals - time between sequential outbound transfers')\n"
      ],
      "metadata": {
        "id": "WdMo6qwCtpTt",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Observed temporal patterns are assessed. Here regular intervals and\n",
        "#consistent transaction sizing may indicate payroll-like disbursement,\n",
        "#while highly variable intervals suggest ad-hoc liquidation or laundering\n",
        "outbound_count_per_wallet_df = db.sql('''\n",
        "SELECT wallet_address, COUNT(*) AS tx_count, SUM(value_eth) AS value_eth\n",
        "FROM outbound_flows_df\n",
        "GROUP BY wallet_address\n",
        "ORDER BY tx_count DESC, value_eth DESC;''').df()\n",
        "\n",
        "#Additional diagnostics include per-wallet transaction counts and\n",
        "#day-of-month frequency analysis to identify preferential transaction\n",
        "#windows indicative of structured operational cycles\n",
        "\n",
        "outbound_count_per_wallet_df_1 = db.sql('''\n",
        "SELECT wallet_address, tx_count, value_eth\n",
        "FROM outbound_count_per_wallet_df\n",
        "WHERE tx_count > 1\n",
        "ORDER BY tx_count DESC, value_eth DESC;''').df()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1I9s42IQKo2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Enrichment of Data: Value-Based Behaviour Analysis"
      ],
      "metadata": {
        "id": "sinNr0iP1XDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To enable cross-period comparison and mitigate the effects of ETH price volatility,\n",
        "#transaction values are converted from ETH to USD using daily ETH-USD pricing data from yfinance library\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "#Fetching historical ETH-USD pricing data using yfinance\n",
        "#The date range is chosen to cover potential transaction dates\n",
        "raw_eth_pricing_df = yf.Ticker(\"ETH-USD\")\n",
        "raw_eth_pricing_df = raw_eth_pricing_df.history(start=\"2020-08-17\", end=\"2026-01-07\", interval=\"1d\")\n",
        "raw_eth_pricing_df.reset_index(inplace=True)\n",
        "raw_eth_pricing_df = raw_eth_pricing_df.rename(columns={'Date': 'eth_date'})\n",
        "\n",
        "#The daily 'high' price estimate is considered\n",
        "eth_daily_prices_df = db.sql('''\n",
        "SELECT eth_date, High AS eth_price\n",
        "FROM raw_eth_pricing_df;''').df()\n",
        "\n",
        "#Pricing data is joined to transaction records based on transaction date\n",
        "transactions_with_price = db.sql('''\n",
        "SELECT\n",
        "t1.ts,\n",
        "t1.tx_hash,\n",
        "t1.from_address,\n",
        "t1.to_address,\n",
        "t1.value_eth,\n",
        "t2.eth_date,\n",
        "t2.eth_price,\n",
        "ROUND((value_eth * eth_price), 2) AS ETH_USD -- Calculate transaction value in USD\n",
        "FROM clean_dataset_df as t1\n",
        "LEFT JOIN eth_daily_prices_df as t2\n",
        "ON (date(t1.ts) = date(t2.eth_date)); -- Join on date part of timestamp\n",
        "''').df()\n",
        "\n",
        "#Pricing data with outbound flows is specifically enriched\n",
        "outbound_flows_with_price_df = db.sql('''\n",
        "SELECT\n",
        "t1.ts,\n",
        "t1.tx_hash,\n",
        "t1.wallet_address,\n",
        "t1.recipient_address,\n",
        "t1.value_eth,\n",
        "t2.eth_price,\n",
        "t2.ETH_USD\n",
        "FROM outbound_flows_df as t1\n",
        "LEFT JOIN transactions_with_price as t2\n",
        "ON t1.tx_hash = t2.tx_hash;''').df()"
      ],
      "metadata": {
        "id": "c2JHeujEm-LR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Monthly Clustering Analysis & visualisation"
      ],
      "metadata": {
        "id": "9QcEy3jBMiy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This analysis assesses whether outbound transaction activity exhibits\n",
        "#recurring concentration within specific windows of the calendar month,\n",
        "#which may be indicative of salary disbursement cycles.\n",
        "\n",
        "#Transaction timestamps are decomposed to extract the day-of-month and\n",
        "#grouped into early, mid and late-month buckets to capture realistic\n",
        "#payroll behaviour rather than exact calendar dates.\n",
        "\n",
        "monthly_clustering_df = db.sql('''\n",
        "SELECT\n",
        "wallet_address,\n",
        "YEAR(ts) AS year,\n",
        "DAYOFMONTH(ts) AS day_of_month,\n",
        "CASE\n",
        "WHEN DAYOFMONTH(ts) BETWEEN 1 AND 5 THEN 'Early'\n",
        "WHEN DAYOFMONTH(ts) BETWEEN 25 AND 31 THEN 'Late'\n",
        "ELSE 'Mid-Month'\n",
        "END AS clustering_period,\n",
        "CASE\n",
        "WHEN ETH_USD < 2000 THEN '<$2K'\n",
        "WHEN ETH_USD BETWEEN 2000 AND 5000 THEN '$2K-$5K'\n",
        "ELSE '>$5K'\n",
        "END AS value_band,\n",
        "COUNT(*) AS tx_count,\n",
        "SUM(value_eth) AS total_value_eth_USD,\n",
        "AVG(value_eth) AS avg_value_eth_USD,\n",
        "FROM outbound_flows_with_price_df\n",
        "GROUP BY wallet_address, DAYOFMONTH(ts), Year(ts), clustering_period, value_band\n",
        "ORDER BY year, tx_count, clustering_period, value_band DESC;''').df()\n",
        "\n",
        "\n",
        "#This query aggregates all outbound transactions by day of the month, calculating total counts and average/summed USD values.\n",
        "#This provides an overall view of transaction frequency and value distribution across the days of a month.\n",
        "aggregated_monthly_clustering_df = db.sql('''\n",
        "SELECT DAYOFMONTH(ts) AS Day_of_month, COUNT(*) AS tx_count, AVG(value_eth) AS avg_value_eth, AVG(ETH_USD) AS value_eth_usd, SUM(ETH_USD) AS total_value_eth_usd\n",
        "FROM outbound_flows_with_price_df\n",
        "GROUP BY DAYOFMONTH(ts)\n",
        "ORDER BY Day_of_month;''').df()\n",
        "\n",
        "\n",
        "\n",
        "#agg yearly count of transactions over total transactions of all years * 100\n",
        "aggregated_monthly_clustering_df_1 = db.sql('''\n",
        "WITH yearly_counts AS (\n",
        "SELECT COUNT(*) AS tx_count, YEAR(ts) AS year, SUM(value_eth) AS total_value_eth, SUM(ETH_USD) AS total_ETH_USD\n",
        "FROM outbound_flows_with_price_df\n",
        "GROUP BY YEAR(ts)\n",
        ")\n",
        "SELECT year, tx_count, SUM(tx_count) OVER() AS total_tx_count, ROUND((tx_count/total_tx_count)*100, 2) AS percentage_tx_count,\n",
        "SUM(total_value_eth) OVER () AS tvs, SUM(total_ETH_USD) OVER () AS teu, (total_value_eth/tvs)* 100 AS percentrage_tvs,\n",
        "(total_ETH_USD/teu)* 100 AS percentrage_teu\n",
        "FROM yearly_counts\n",
        "ORDER BY year\n",
        ";''').df()\n",
        "\n",
        "\n",
        "##visualisation1\n",
        "import plotly.express as px\n",
        "\n",
        "#Creating a stacked bar chart for transaction counts by clustering period and value band.\n",
        "#This chart shows how many transactions fall into each monthly period (early, mid, late) and value range (<$2K, $2K-$5K, >$5K).\n",
        "fig_tx_count = px.bar(monthly_clustering_df,\n",
        "                      x=\"clustering_period\",\n",
        "                      y=\"tx_count\",\n",
        "                      color=\"value_band\",\n",
        "                      barmode=\"stack\",\n",
        "                      title=\"Monthly Outbound Transaction Count by Clustering Period and Value Band\",\n",
        "                      labels={\"clustering_period\": \"Clustering Period\",\n",
        "                              \"tx_count\": \"transaction Count\",\n",
        "                              \"value_band\": \"Value Band\"},\n",
        "                      height=500)\n",
        "\n",
        "\n",
        "\n",
        "#Creating a stacked bar chart for total ETH_USD value by clustering period and value band.\n",
        "#This chart visualises the total monetary value transferred within each monthly period and value range.\n",
        "fig_total_value = px.bar(monthly_clustering_df,\n",
        "                      x=\"clustering_period\",\n",
        "                      y=\"total_value_eth_USD\",\n",
        "                      color=\"value_band\",\n",
        "                      barmode=\"stack\",\n",
        "                      title=\"Monthly Outbound Total Value in USD by Clustering Period and Value Band\",\n",
        "                      labels={\"clustering_period\": \"Clustering Period\",\n",
        "                              \"total_value_eth_USD\": \"Total ETH_USD Value\",\n",
        "                              \"value_band\": \"Value Band\"},\n",
        "                      height=500)\n",
        "\n",
        "\n",
        "\n",
        "##visualisation2\n",
        "import plotly.express as px\n",
        "\n",
        "df = px.data.tips()\n",
        "\n",
        "#Creating a stacked bar chart for transaction counts faceted by year.\n",
        "#This allows for comparison of transaction frequency patterns across different years.\n",
        "fig_tx_count = px.bar(monthly_clustering_df,\n",
        "                      x=\"clustering_period\",\n",
        "                      y=\"tx_count\",\n",
        "                      color=\"value_band\",\n",
        "                      barmode=\"stack\",\n",
        "                      facet_col=\"year\",\n",
        "                      title=\"Yearly-Monthly Outbound Transaction Count by Clustering Period and Value Band\",\n",
        "                      labels={\"clustering_period\": \"Clustering Period\",\n",
        "                              \"tx_count\": \"transaction Count\",\n",
        "                              \"value_band\": \"Value Band\"},\n",
        "                      height=500)\n",
        "\n",
        "\n",
        "\n",
        "#Creating a stacked bar chart for total ETH_USD value faceted by year.\n",
        "#This allows for comparison of total value transferred patterns across different years.\n",
        "fig_total_value = px.bar(monthly_clustering_df,\n",
        "                      x=\"clustering_period\",\n",
        "                      y=\"total_value_eth_USD\",\n",
        "                      color=\"value_band\",\n",
        "                      barmode=\"stack\",\n",
        "                      facet_col=\"year\",\n",
        "                      title=\"Yearly-Monthly Outbound Total Value in USD by Clustering Period and Value Band\",\n",
        "                      labels={\"clustering_period\": \"Clustering Period\",\n",
        "                              \"total_value_eth_USD\": \"Total ETH_USD Value\",\n",
        "                              \"value_band\": \"Value Band\"},\n",
        "                      height=500)\n",
        "\n",
        "\n",
        "##visualisation3\n",
        "#Outbound frequency distribution by day of month\n",
        "fig = px.bar(aggregated_monthly_clustering_df, y='tx_count', x='Day_of_month', text_auto='.2s',\n",
        "            title=\"Outbound Transaction Frequency by Day of Month\")\n",
        "fig.update_traces(textfont_size=12, textangle=0, textposition=\"inside\", cliponaxis=False)\n",
        "fig.update_layout(xaxis_title=\"Day of Month\", yaxis_title=\"Number of Transactions\", xaxis=dict(tickmode='linear', tick0=1, dtick=1))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vDJ8SmuoH__5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}